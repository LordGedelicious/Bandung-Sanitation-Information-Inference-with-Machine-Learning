{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary basic libraries\n",
    "# Libraries will be added as needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data from CSV file and Split into Train and Test\n",
    "sni_df = pd.read_csv('data/sni.csv', dtype={'Target Class': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 27 columns):\n",
      " #   Column                                             Non-Null Count   Dtype  \n",
      "---  ------                                             --------------   -----  \n",
      " 0   ID                                                 100000 non-null  int64  \n",
      " 1   Tangki Septik_Penggunaan                           79971 non-null   object \n",
      " 2   Tangki Septik_Terawat                              80001 non-null   object \n",
      " 3   Tangki Septik_Bau Tidak Sedap                      80069 non-null   object \n",
      " 4   Tangki Septik_Ketercemaran Lingkungan              80011 non-null   object \n",
      " 5   Tangki Septik_Jarak Dari Sumber Air (m)            100000 non-null  float64\n",
      " 6   Sarana Pembuangan BAB_Penggunaan                   80201 non-null   object \n",
      " 7   Sarana Pembuangan BAB_Bangunan Terawat             79921 non-null   object \n",
      " 8   Sarana Pembuangan BAB_Keberadaan Dinding Bangunan  80041 non-null   object \n",
      " 9   Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu   79956 non-null   object \n",
      " 10  Sarana Pembuangan BAB_Penerangan yang Cukup        80183 non-null   object \n",
      " 11  Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa  80142 non-null   object \n",
      " 12  Sarana Pembuangan BAB_Terdapat Sarana Air Bersih   80084 non-null   object \n",
      " 13  IPLT_Penggunaan                                    79734 non-null   object \n",
      " 14  IPLT_Bangunan Terawat                              79833 non-null   object \n",
      " 15  IPLT_Bau Tidak Sedap                               79960 non-null   object \n",
      " 16  IPLT_Pencemaran Lingkungan                         79833 non-null   object \n",
      " 17  IPLT_Air Limbah Berwarna                           79741 non-null   object \n",
      " 18  IPLT_Jarak Dari Permukiman (km)                    100000 non-null  float64\n",
      " 19  Saluran Drainase_Hierarki Drainase                 85841 non-null   object \n",
      " 20  Saluran Drainase_Jenis Drainase                    79867 non-null   object \n",
      " 21  Saluran Drainase_Bentuk Penampang                  88862 non-null   object \n",
      " 22  Saluran Drainase_Perkerasan Tepi Drainase          91036 non-null   object \n",
      " 23  Saluran Drainase_Kondisi Drainase                  80063 non-null   object \n",
      " 24  Saluran Drainase_Bau Tidak Sedap                   79784 non-null   object \n",
      " 25  Saluran Drainase_Sedimentasi Drainase              88956 non-null   object \n",
      " 26  Target Class                                       100000 non-null  object \n",
      "dtypes: float64(2), int64(1), object(24)\n",
      "memory usage: 20.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Perform Exploratory Data Analysis\n",
    "# Check data types, missing values, etc.\n",
    "sni_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID Tangki Septik_Penggunaan Tangki Septik_Terawat   \n",
      "0   0          Tidak Berfungsi                 Tidak  \\\n",
      "1   1          Tidak Berfungsi                    Ya   \n",
      "2   2          Tidak Berfungsi                   NaN   \n",
      "3   3          Tidak Berfungsi                 Tidak   \n",
      "4   4                Berfungsi                   NaN   \n",
      "\n",
      "  Tangki Septik_Bau Tidak Sedap Tangki Septik_Ketercemaran Lingkungan   \n",
      "0                            Ya                                   NaN  \\\n",
      "1                            Ya                                   NaN   \n",
      "2                         Tidak                                    Ya   \n",
      "3                            Ya                                 Tidak   \n",
      "4                            Ya                                   NaN   \n",
      "\n",
      "   Tangki Septik_Jarak Dari Sumber Air (m) Sarana Pembuangan BAB_Penggunaan   \n",
      "0                                     6.06                              NaN  \\\n",
      "1                                    12.00                  Tidak Berfungsi   \n",
      "2                                    41.23                        Berfungsi   \n",
      "3                                    49.59                  Tidak Berfungsi   \n",
      "4                                    10.93                        Berfungsi   \n",
      "\n",
      "  Sarana Pembuangan BAB_Bangunan Terawat   \n",
      "0                                     Ya  \\\n",
      "1                                     Ya   \n",
      "2                                     Ya   \n",
      "3                                  Tidak   \n",
      "4                                     Ya   \n",
      "\n",
      "  Sarana Pembuangan BAB_Keberadaan Dinding Bangunan   \n",
      "0                                                Ya  \\\n",
      "1                                                Ya   \n",
      "2                                                Ya   \n",
      "3                                             Tidak   \n",
      "4                                             Tidak   \n",
      "\n",
      "  Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu  ...   \n",
      "0                                               Ya  ...  \\\n",
      "1                                            Tidak  ...   \n",
      "2                                              NaN  ...   \n",
      "3                                              NaN  ...   \n",
      "4                                               Ya  ...   \n",
      "\n",
      "  IPLT_Air Limbah Berwarna IPLT_Jarak Dari Permukiman (km)   \n",
      "0                    Tidak                            0.11  \\\n",
      "1                       Ya                            9.16   \n",
      "2                       Ya                            7.26   \n",
      "3                    Tidak                           17.95   \n",
      "4                       Ya                            2.15   \n",
      "\n",
      "  Saluran Drainase_Hierarki Drainase Saluran Drainase_Jenis Drainase   \n",
      "0                             Primer                             NaN  \\\n",
      "1                             Primer                             NaN   \n",
      "2                            Tersier                        Tertutup   \n",
      "3                           Sekunder                        Tertutup   \n",
      "4                           Sekunder                        Tertutup   \n",
      "\n",
      "  Saluran Drainase_Bentuk Penampang Saluran Drainase_Perkerasan Tepi Drainase   \n",
      "0                           Persegi                                     Tanah  \\\n",
      "1                         Trapesiun                                    Batuan   \n",
      "2                          Segitiga                                    Batuan   \n",
      "3                          Segitiga                                    Batuan   \n",
      "4                          Segitiga                                     Tanah   \n",
      "\n",
      "  Saluran Drainase_Kondisi Drainase Saluran Drainase_Bau Tidak Sedap   \n",
      "0                           Terawat                            Tidak  \\\n",
      "1                     Tidak Terawat                            Tidak   \n",
      "2                     Tidak Terawat                               Ya   \n",
      "3                               NaN                               Ya   \n",
      "4                               NaN                            Tidak   \n",
      "\n",
      "   Saluran Drainase_Sedimentasi Drainase Target Class  \n",
      "0                                 Sampah         0001  \n",
      "1                                  Tanah         0000  \n",
      "2                              Tidak Ada         0001  \n",
      "3                                  Tanah         0000  \n",
      "4                           Eceng Gondok         0000  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sni_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 31 columns):\n",
      " #   Column                                             Non-Null Count   Dtype  \n",
      "---  ------                                             --------------   -----  \n",
      " 0   ID                                                 100000 non-null  int64  \n",
      " 1   Tangki Septik_Penggunaan                           79971 non-null   object \n",
      " 2   Tangki Septik_Terawat                              80001 non-null   object \n",
      " 3   Tangki Septik_Bau Tidak Sedap                      80069 non-null   object \n",
      " 4   Tangki Septik_Ketercemaran Lingkungan              80011 non-null   object \n",
      " 5   Tangki Septik_Jarak Dari Sumber Air (m)            100000 non-null  float64\n",
      " 6   Sarana Pembuangan BAB_Penggunaan                   80201 non-null   object \n",
      " 7   Sarana Pembuangan BAB_Bangunan Terawat             79921 non-null   object \n",
      " 8   Sarana Pembuangan BAB_Keberadaan Dinding Bangunan  80041 non-null   object \n",
      " 9   Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu   79956 non-null   object \n",
      " 10  Sarana Pembuangan BAB_Penerangan yang Cukup        80183 non-null   object \n",
      " 11  Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa  80142 non-null   object \n",
      " 12  Sarana Pembuangan BAB_Terdapat Sarana Air Bersih   80084 non-null   object \n",
      " 13  IPLT_Penggunaan                                    79734 non-null   object \n",
      " 14  IPLT_Bangunan Terawat                              79833 non-null   object \n",
      " 15  IPLT_Bau Tidak Sedap                               79960 non-null   object \n",
      " 16  IPLT_Pencemaran Lingkungan                         79833 non-null   object \n",
      " 17  IPLT_Air Limbah Berwarna                           79741 non-null   object \n",
      " 18  IPLT_Jarak Dari Permukiman (km)                    100000 non-null  float64\n",
      " 19  Saluran Drainase_Hierarki Drainase                 85841 non-null   object \n",
      " 20  Saluran Drainase_Jenis Drainase                    79867 non-null   object \n",
      " 21  Saluran Drainase_Bentuk Penampang                  88862 non-null   object \n",
      " 22  Saluran Drainase_Perkerasan Tepi Drainase          91036 non-null   object \n",
      " 23  Saluran Drainase_Kondisi Drainase                  80063 non-null   object \n",
      " 24  Saluran Drainase_Bau Tidak Sedap                   79784 non-null   object \n",
      " 25  Saluran Drainase_Sedimentasi Drainase              88956 non-null   object \n",
      " 26  Target Class                                       100000 non-null  object \n",
      " 27  Tangki Septik_Class                                100000 non-null  object \n",
      " 28  Sarana Pembuangan BAB_Class                        100000 non-null  object \n",
      " 29  IPLT/IPAL_Class                                    100000 non-null  object \n",
      " 30  Saluran Drainase_Class                             100000 non-null  object \n",
      "dtypes: float64(2), int64(1), object(28)\n",
      "memory usage: 23.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# From domain knowledge, we know that target class is a categorical variable type of string\n",
    "# The value follows a format of \"ABCD\" with A, B, C, D are either 0 or 1\n",
    "# If A is 1, then it means that \"Tangki Septik\" is \"Layak\". Else, it is \"Tidak Layak\"\n",
    "# If B is 1, then it means that \"Sarana Pembuangan BAB\" is \"Layak\". Else, it is \"Tidak Layak\"\n",
    "# If C is 1, then it means that \"IPLT/IPAL\" is \"Layak\". Else, it is \"Tidak Layak\"\n",
    "# If D is 1, then it means that \"Saluran Drainase\" is \"Layak\". Else, it is \"Tidak Layak\"\n",
    "# Since the target consists of multiple sub-targets, we will split the target into 4 columns. and then the data itself\n",
    "\n",
    "# Create the new columns\n",
    "sni_df['Tangki Septik_Class'] = ''\n",
    "sni_df['Sarana Pembuangan BAB_Class'] = ''\n",
    "sni_df['IPLT/IPAL_Class'] = ''\n",
    "sni_df['Saluran Drainase_Class'] = ''\n",
    "\n",
    "# Initialize the new columns with the contents\n",
    "sni_df['Tangki Septik_Class'] = sni_df['Target Class'].str[0]\n",
    "sni_df['Sarana Pembuangan BAB_Class'] = sni_df['Target Class'].str[1]\n",
    "sni_df['IPLT/IPAL_Class'] = sni_df['Target Class'].str[2]\n",
    "sni_df['Saluran Drainase_Class'] = sni_df['Target Class'].str[3]\n",
    "\n",
    "# Check results\n",
    "sni_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates 4 different dataframes for each target\n",
    "sni_tangki_septik_range = [1, 2, 3, 4, 5]\n",
    "sni_sp_bab_range = [6, 7, 8, 9, 10, 11, 12]\n",
    "sni_iplt_range = [13, 14, 15, 16, 17, 18]\n",
    "sni_drainase_range = [19, 20, 21, 22, 23, 24, 25]\n",
    "\n",
    "sni_tangki_septik = sni_df.iloc[:, sni_tangki_septik_range + [-4]]\n",
    "sni_sp_bab = sni_df.iloc[:, sni_sp_bab_range + [-3]]\n",
    "sni_iplt = sni_df.iloc[:, sni_iplt_range + [-2]]\n",
    "sni_drainase = sni_df.iloc[:, sni_drainase_range + [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                   Non-Null Count   Dtype  \n",
      "---  ------                                   --------------   -----  \n",
      " 0   Tangki Septik_Penggunaan                 79971 non-null   object \n",
      " 1   Tangki Septik_Terawat                    80001 non-null   object \n",
      " 2   Tangki Septik_Bau Tidak Sedap            80069 non-null   object \n",
      " 3   Tangki Septik_Ketercemaran Lingkungan    80011 non-null   object \n",
      " 4   Tangki Septik_Jarak Dari Sumber Air (m)  100000 non-null  float64\n",
      " 5   Tangki Septik_Class                      100000 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 4.6+ MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                             Non-Null Count   Dtype \n",
      "---  ------                                             --------------   ----- \n",
      " 0   Sarana Pembuangan BAB_Penggunaan                   80201 non-null   object\n",
      " 1   Sarana Pembuangan BAB_Bangunan Terawat             79921 non-null   object\n",
      " 2   Sarana Pembuangan BAB_Keberadaan Dinding Bangunan  80041 non-null   object\n",
      " 3   Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu   79956 non-null   object\n",
      " 4   Sarana Pembuangan BAB_Penerangan yang Cukup        80183 non-null   object\n",
      " 5   Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa  80142 non-null   object\n",
      " 6   Sarana Pembuangan BAB_Terdapat Sarana Air Bersih   80084 non-null   object\n",
      " 7   Sarana Pembuangan BAB_Class                        100000 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   IPLT_Penggunaan                  79734 non-null   object \n",
      " 1   IPLT_Bangunan Terawat            79833 non-null   object \n",
      " 2   IPLT_Bau Tidak Sedap             79960 non-null   object \n",
      " 3   IPLT_Pencemaran Lingkungan       79833 non-null   object \n",
      " 4   IPLT_Air Limbah Berwarna         79741 non-null   object \n",
      " 5   IPLT_Jarak Dari Permukiman (km)  100000 non-null  float64\n",
      " 6   IPLT/IPAL_Class                  100000 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 5.3+ MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                     Non-Null Count   Dtype \n",
      "---  ------                                     --------------   ----- \n",
      " 0   Saluran Drainase_Hierarki Drainase         85841 non-null   object\n",
      " 1   Saluran Drainase_Jenis Drainase            79867 non-null   object\n",
      " 2   Saluran Drainase_Bentuk Penampang          88862 non-null   object\n",
      " 3   Saluran Drainase_Perkerasan Tepi Drainase  91036 non-null   object\n",
      " 4   Saluran Drainase_Kondisi Drainase          80063 non-null   object\n",
      " 5   Saluran Drainase_Bau Tidak Sedap           79784 non-null   object\n",
      " 6   Saluran Drainase_Sedimentasi Drainase      88956 non-null   object\n",
      " 7   Saluran Drainase_Class                     100000 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check results\n",
    "print(sni_tangki_septik.info())\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(sni_sp_bab.info())\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(sni_iplt.info())\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(sni_drainase.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, split the data into train and test\n",
    "sni_tangki_septik_train, sni_tangki_septik_test = train_test_split(sni_tangki_septik, test_size=0.2, random_state=42)\n",
    "sni_sp_bab_train, sni_sp_bab_test = train_test_split(sni_sp_bab, test_size=0.2, random_state=42)\n",
    "sni_iplt_train, sni_iplt_test = train_test_split(sni_iplt, test_size=0.2, random_state=42)\n",
    "sni_drainase_train, sni_drainase_test = train_test_split(sni_drainase, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Duplicate rows in Tangki Septik database:9599\n",
      "Percentage of duplicate rows in Tangki Septik database:12.0%\n",
      "------------------------------------------------------------------\n",
      "Duplicate rows in Sarana Pembuangan BAB database:77820\n",
      "Percentage of duplicate rows in Sarana Pembuangan BAB database:97.28%\n",
      "------------------------------------------------------------------\n",
      "Duplicate rows in IPLT/IPAL database:8659\n",
      "Percentage of duplicate rows in IPLT/IPAL database:10.82%\n",
      "------------------------------------------------------------------\n",
      "Duplicate rows in Saluran Drainase database:65154\n",
      "Percentage of duplicate rows in Saluran Drainase database:81.44%\n"
     ]
    }
   ],
   "source": [
    "# Now, preprocess the training data for machine learning modelling\n",
    "# We need to find duplicate rows in each database and count them to make sure they're of random instances instead of results of the natural variations since the data is computer-generated\n",
    "# Also delete them, as it will reduce overfitting and reduce model's training time and bias\n",
    "database_title = [\"Tangki Septik\", \"Sarana Pembuangan BAB\", \"IPLT/IPAL\", \"Saluran Drainase\"]\n",
    "database = [sni_tangki_septik_train, sni_sp_bab_train, sni_iplt_train, sni_drainase_train]\n",
    "\n",
    "for data_idx in range(len(database)):\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(\"Duplicate rows in \" + database_title[data_idx] + \" database:\" + str(database[data_idx].duplicated().sum()))\n",
    "    print(\"Percentage of duplicate rows in \" + database_title[data_idx] + \" database:\" + str(round(database[data_idx].duplicated().sum() / len(database[data_idx]) * 100, 2)) + \"%\")\n",
    "    database[data_idx] = database[data_idx].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Currently processing: Tangki Septik\n",
      "------------------------------------------------------------------\n",
      "Column Tangki Septik_Penggunaan has 14959 missing values. Percentage from total length: 21.248277723327792\n",
      "Column Tangki Septik_Penggunaan has 3 unique values.\n",
      "\n",
      "Column Tangki Septik_Terawat has 14887 missing values. Percentage from total length: 21.146006448772035\n",
      "Column Tangki Septik_Terawat has 3 unique values.\n",
      "\n",
      "Column Tangki Septik_Bau Tidak Sedap has 14851 missing values. Percentage from total length: 21.094870811494154\n",
      "Column Tangki Septik_Bau Tidak Sedap has 3 unique values.\n",
      "\n",
      "Column Tangki Septik_Ketercemaran Lingkungan has 14858 missing values. Percentage from total length: 21.104813852075964\n",
      "Column Tangki Septik_Ketercemaran Lingkungan has 3 unique values.\n",
      "\n",
      "Column Tangki Septik_Jarak Dari Sumber Air (m) has 0 missing values. Percentage from total length: 0.0\n",
      "Column Tangki Septik_Jarak Dari Sumber Air (m) has 5001 unique values.\n",
      "\n",
      "Column Tangki Septik_Class has 0 missing values. Percentage from total length: 0.0\n",
      "Column Tangki Septik_Class has 2 unique values.\n",
      "\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Currently processing: Sarana Pembuangan BAB\n",
      "------------------------------------------------------------------\n",
      "Column Sarana Pembuangan BAB_Penggunaan has 723 missing values. Percentage from total length: 33.1651376146789\n",
      "Column Sarana Pembuangan BAB_Penggunaan has 3 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Bangunan Terawat has 724 missing values. Percentage from total length: 33.211009174311926\n",
      "Column Sarana Pembuangan BAB_Bangunan Terawat has 3 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Keberadaan Dinding Bangunan has 723 missing values. Percentage from total length: 33.1651376146789\n",
      "Column Sarana Pembuangan BAB_Keberadaan Dinding Bangunan has 3 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu has 725 missing values. Percentage from total length: 33.25688073394495\n",
      "Column Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu has 3 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Penerangan yang Cukup has 724 missing values. Percentage from total length: 33.211009174311926\n",
      "Column Sarana Pembuangan BAB_Penerangan yang Cukup has 3 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa has 722 missing values. Percentage from total length: 33.11926605504587\n",
      "Column Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa has 3 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Terdapat Sarana Air Bersih has 725 missing values. Percentage from total length: 33.25688073394495\n",
      "Column Sarana Pembuangan BAB_Terdapat Sarana Air Bersih has 3 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Class has 0 missing values. Percentage from total length: 0.0\n",
      "Column Sarana Pembuangan BAB_Class has 2 unique values.\n",
      "\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Currently processing: IPLT/IPAL\n",
      "------------------------------------------------------------------\n",
      "Column IPLT_Penggunaan has 15224 missing values. Percentage from total length: 21.339762548884934\n",
      "Column IPLT_Penggunaan has 3 unique values.\n",
      "\n",
      "Column IPLT_Bangunan Terawat has 15060 missing values. Percentage from total length: 21.109880713755064\n",
      "Column IPLT_Bangunan Terawat has 3 unique values.\n",
      "\n",
      "Column IPLT_Bau Tidak Sedap has 15060 missing values. Percentage from total length: 21.109880713755064\n",
      "Column IPLT_Bau Tidak Sedap has 3 unique values.\n",
      "\n",
      "Column IPLT_Pencemaran Lingkungan has 15152 missing values. Percentage from total length: 21.238838816388895\n",
      "Column IPLT_Pencemaran Lingkungan has 3 unique values.\n",
      "\n",
      "Column IPLT_Air Limbah Berwarna has 15093 missing values. Percentage from total length: 21.156137424482417\n",
      "Column IPLT_Air Limbah Berwarna has 3 unique values.\n",
      "\n",
      "Column IPLT_Jarak Dari Permukiman (km) has 0 missing values. Percentage from total length: 0.0\n",
      "Column IPLT_Jarak Dari Permukiman (km) has 2001 unique values.\n",
      "\n",
      "Column IPLT/IPAL_Class has 0 missing values. Percentage from total length: 0.0\n",
      "Column IPLT/IPAL_Class has 2 unique values.\n",
      "\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Currently processing: Saluran Drainase\n",
      "------------------------------------------------------------------\n",
      "Column Saluran Drainase_Hierarki Drainase has 3390 missing values. Percentage from total length: 22.834433517445778\n",
      "Column Saluran Drainase_Hierarki Drainase has 4 unique values.\n",
      "\n",
      "Column Saluran Drainase_Jenis Drainase has 4637 missing values. Percentage from total length: 31.234002424895596\n",
      "Column Saluran Drainase_Jenis Drainase has 3 unique values.\n",
      "\n",
      "Column Saluran Drainase_Bentuk Penampang has 2696 missing values. Percentage from total length: 18.159773676411152\n",
      "Column Saluran Drainase_Bentuk Penampang has 5 unique values.\n",
      "\n",
      "Column Saluran Drainase_Perkerasan Tepi Drainase has 2205 missing values. Percentage from total length: 14.852485517984643\n",
      "Column Saluran Drainase_Perkerasan Tepi Drainase has 6 unique values.\n",
      "\n",
      "Column Saluran Drainase_Kondisi Drainase has 4610 missing values. Percentage from total length: 31.05213525528762\n",
      "Column Saluran Drainase_Kondisi Drainase has 3 unique values.\n",
      "\n",
      "Column Saluran Drainase_Bau Tidak Sedap has 4590 missing values. Percentage from total length: 30.917418833355786\n",
      "Column Saluran Drainase_Bau Tidak Sedap has 3 unique values.\n",
      "\n",
      "Column Saluran Drainase_Sedimentasi Drainase has 2672 missing values. Percentage from total length: 17.998113970092955\n",
      "Column Saluran Drainase_Sedimentasi Drainase has 5 unique values.\n",
      "\n",
      "Column Saluran Drainase_Class has 0 missing values. Percentage from total length: 0.0\n",
      "Column Saluran Drainase_Class has 2 unique values.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find missing values and then decides what to do with it\n",
    "for data_idx in range(len(database)):\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(\"Currently processing: \" + database_title[data_idx])\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    data = database[data_idx]\n",
    "    length_data = len(data)\n",
    "    for col in data.columns:\n",
    "        print(\"Column {} has {} missing values. Percentage from total length: {}\".format(col, data[col].isnull().sum(), data[col].isnull().sum()/length_data*100))\n",
    "        print(\"Column {} has {} unique values.\".format(col, len(data[col].unique())))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Currently processing: Tangki Septik\n",
      "Old length of the data is: 70401\n",
      "New length of the data is: 68236\n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Currently processing: Sarana Pembuangan BAB\n",
      "Old length of the data is: 2180\n",
      "New length of the data is: 2087\n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Currently processing: IPLT/IPAL\n",
      "Old length of the data is: 71341\n",
      "New length of the data is: 70814\n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Currently processing: Saluran Drainase\n",
      "Old length of the data is: 14846\n",
      "New length of the data is: 14771\n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since there's a large percentage of missing values, it is impossible to fill them with the mean or median as it can ruin the distribution of the data\n",
    "# We will drop the rows with too many missing values. Definition of too many is 50% of the total length of the data excluding the target class\n",
    "for data_idx in range(len(database)):\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(\"Currently processing: \" + database_title[data_idx])\n",
    "    print(\"Old length of the data is: \" + str(len(database[data_idx])))\n",
    "    data = database[data_idx]\n",
    "    width_data = len(data.columns) - 1 # Exclude the target class\n",
    "    threshold = round(width_data * 0.5)\n",
    "    data = data.dropna(thresh=width_data - threshold + 1) \n",
    "    print(\"New length of the data is: \" + str(len(data)))\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Currently processing: Tangki Septik\n",
      "------------------------------------------------------------------\n",
      "Column Tangki Septik_Penggunaan has 0 missing values. Percentage from total length: 0.0\n",
      "Column Tangki Septik_Penggunaan has 2 unique values.\n",
      "\n",
      "Column Tangki Septik_Terawat has 0 missing values. Percentage from total length: 0.0\n",
      "Column Tangki Septik_Terawat has 2 unique values.\n",
      "\n",
      "Column Tangki Septik_Bau Tidak Sedap has 0 missing values. Percentage from total length: 0.0\n",
      "Column Tangki Septik_Bau Tidak Sedap has 2 unique values.\n",
      "\n",
      "Column Tangki Septik_Ketercemaran Lingkungan has 0 missing values. Percentage from total length: 0.0\n",
      "Column Tangki Septik_Ketercemaran Lingkungan has 2 unique values.\n",
      "\n",
      "Column Tangki Septik_Jarak Dari Sumber Air (m) has 0 missing values. Percentage from total length: 0.0\n",
      "Column Tangki Septik_Jarak Dari Sumber Air (m) has 5001 unique values.\n",
      "\n",
      "Column Tangki Septik_Class has 0 missing values. Percentage from total length: 0.0\n",
      "Column Tangki Septik_Class has 2 unique values.\n",
      "\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Currently processing: Sarana Pembuangan BAB\n",
      "------------------------------------------------------------------\n",
      "Column Sarana Pembuangan BAB_Penggunaan has 0 missing values. Percentage from total length: 0.0\n",
      "Column Sarana Pembuangan BAB_Penggunaan has 2 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Bangunan Terawat has 0 missing values. Percentage from total length: 0.0\n",
      "Column Sarana Pembuangan BAB_Bangunan Terawat has 2 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Keberadaan Dinding Bangunan has 0 missing values. Percentage from total length: 0.0\n",
      "Column Sarana Pembuangan BAB_Keberadaan Dinding Bangunan has 2 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu has 0 missing values. Percentage from total length: 0.0\n",
      "Column Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu has 2 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Penerangan yang Cukup has 0 missing values. Percentage from total length: 0.0\n",
      "Column Sarana Pembuangan BAB_Penerangan yang Cukup has 2 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa has 0 missing values. Percentage from total length: 0.0\n",
      "Column Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa has 2 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Terdapat Sarana Air Bersih has 0 missing values. Percentage from total length: 0.0\n",
      "Column Sarana Pembuangan BAB_Terdapat Sarana Air Bersih has 2 unique values.\n",
      "\n",
      "Column Sarana Pembuangan BAB_Class has 0 missing values. Percentage from total length: 0.0\n",
      "Column Sarana Pembuangan BAB_Class has 2 unique values.\n",
      "\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Currently processing: IPLT/IPAL\n",
      "------------------------------------------------------------------\n",
      "Column IPLT_Penggunaan has 0 missing values. Percentage from total length: 0.0\n",
      "Column IPLT_Penggunaan has 2 unique values.\n",
      "\n",
      "Column IPLT_Bangunan Terawat has 0 missing values. Percentage from total length: 0.0\n",
      "Column IPLT_Bangunan Terawat has 2 unique values.\n",
      "\n",
      "Column IPLT_Bau Tidak Sedap has 0 missing values. Percentage from total length: 0.0\n",
      "Column IPLT_Bau Tidak Sedap has 2 unique values.\n",
      "\n",
      "Column IPLT_Pencemaran Lingkungan has 0 missing values. Percentage from total length: 0.0\n",
      "Column IPLT_Pencemaran Lingkungan has 2 unique values.\n",
      "\n",
      "Column IPLT_Air Limbah Berwarna has 0 missing values. Percentage from total length: 0.0\n",
      "Column IPLT_Air Limbah Berwarna has 2 unique values.\n",
      "\n",
      "Column IPLT_Jarak Dari Permukiman (km) has 0 missing values. Percentage from total length: 0.0\n",
      "Column IPLT_Jarak Dari Permukiman (km) has 2001 unique values.\n",
      "\n",
      "Column IPLT/IPAL_Class has 0 missing values. Percentage from total length: 0.0\n",
      "Column IPLT/IPAL_Class has 2 unique values.\n",
      "\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Currently processing: Saluran Drainase\n",
      "------------------------------------------------------------------\n",
      "Column Saluran Drainase_Hierarki Drainase has 0 missing values. Percentage from total length: 0.0\n",
      "Column Saluran Drainase_Hierarki Drainase has 3 unique values.\n",
      "\n",
      "Column Saluran Drainase_Jenis Drainase has 0 missing values. Percentage from total length: 0.0\n",
      "Column Saluran Drainase_Jenis Drainase has 2 unique values.\n",
      "\n",
      "Column Saluran Drainase_Bentuk Penampang has 0 missing values. Percentage from total length: 0.0\n",
      "Column Saluran Drainase_Bentuk Penampang has 4 unique values.\n",
      "\n",
      "Column Saluran Drainase_Perkerasan Tepi Drainase has 0 missing values. Percentage from total length: 0.0\n",
      "Column Saluran Drainase_Perkerasan Tepi Drainase has 5 unique values.\n",
      "\n",
      "Column Saluran Drainase_Kondisi Drainase has 0 missing values. Percentage from total length: 0.0\n",
      "Column Saluran Drainase_Kondisi Drainase has 2 unique values.\n",
      "\n",
      "Column Saluran Drainase_Bau Tidak Sedap has 0 missing values. Percentage from total length: 0.0\n",
      "Column Saluran Drainase_Bau Tidak Sedap has 2 unique values.\n",
      "\n",
      "Column Saluran Drainase_Sedimentasi Drainase has 0 missing values. Percentage from total length: 0.0\n",
      "Column Saluran Drainase_Sedimentasi Drainase has 4 unique values.\n",
      "\n",
      "Column Saluran Drainase_Class has 0 missing values. Percentage from total length: 0.0\n",
      "Column Saluran Drainase_Class has 2 unique values.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, to process the remaining missing values, we will fill them with the mode of the column\n",
    "for data_idx in range(len(database)):\n",
    "    data = database[data_idx]\n",
    "    length_data = len(data)\n",
    "    for col in data.columns:\n",
    "        data.loc[:, col] = data.loc[:, col].fillna(data.loc[:, col].mode()[0])\n",
    "\n",
    "# Recheck the missing values\n",
    "for data_idx in range(len(database)):\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(\"Currently processing: \" + database_title[data_idx])\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    data = database[data_idx]\n",
    "    length_data = len(data)\n",
    "    for col in data.columns:\n",
    "        print(\"Column {} has {} missing values. Percentage from total length: {}\".format(col, data[col].isnull().sum(), data[col].isnull().sum()/length_data*100))\n",
    "        print(\"Column {} has {} unique values.\".format(col, len(data[col].unique())))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Currently processing: Tangki Septikfor column: Tangki Septik_Jarak Dari Sumber Air (m)\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.0%\n",
      "       Tangki Septik_Jarak Dari Sumber Air (m)\n",
      "count                             8.000000e+04\n",
      "mean                             -2.285563e-03\n",
      "std                               5.802509e-01\n",
      "min                              -1.010571e+00\n",
      "25%                              -5.031712e-01\n",
      "50%                               7.153024e-17\n",
      "75%                               4.968288e-01\n",
      "max                               1.002920e+00\n",
      "------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "Currently processing: IPLT/IPALfor column: IPLT_Jarak Dari Permukiman (km)\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.0%\n",
      "       IPLT_Jarak Dari Permukiman (km)\n",
      "count                     80000.000000\n",
      "mean                          0.001150\n",
      "std                           0.575373\n",
      "min                          -0.995020\n",
      "25%                          -0.498008\n",
      "50%                           0.000000\n",
      "75%                           0.501992\n",
      "max                           0.997012\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Next, we need to check for outliers.\n",
    "# There's only two columns that can be checked for outliers, which are \"Tangki Septik_Jarak Dari Sumber Air (m)\" and \"IPLT_Jarak Dari Permukiman (km)\"\n",
    "# We will also use this opportunity to use StandardScaler to scale the data\n",
    "# For the outlier check, we'll use the IQR method\n",
    "database_title = [\"Tangki Septik\", \"IPLT/IPAL\"]\n",
    "database = [sni_tangki_septik_train, sni_iplt_train]\n",
    "columns = [\"Tangki Septik_Jarak Dari Sumber Air (m)\", \"IPLT_Jarak Dari Permukiman (km)\"]\n",
    "\n",
    "for idx in range(len(database_title)):\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(\"Currently processing: \" + database_title[idx] + \"for column: \" + columns[idx])\n",
    "    data = database[idx]\n",
    "    column_name = columns[idx]\n",
    "    q1 = data[column_name].quantile(0.25)\n",
    "    q3 = data[column_name].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    upper_limit = q3 + 1.5 * iqr\n",
    "    lower_limit = q1 - 1.5 * iqr\n",
    "    outliers = data[(data[column_name] < lower_limit) | (data[column_name] > upper_limit)]\n",
    "    print(\"Number of outliers: \" + str(len(outliers)))\n",
    "    print(\"Percentage of outliers: \" + str(round(len(outliers) / len(data) * 100, 2)) + \"%\")\n",
    "    if len(outliers) == 0:\n",
    "        scaler = RobustScaler()\n",
    "        data[column_name] = scaler.fit_transform(data[column_name].values.reshape(-1, 1))\n",
    "    print(data.describe())\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are no outliers, we can proceed to the next step, which is to split the data into features and target class\n",
    "sni_tangki_septik_train_x = sni_tangki_septik_train.drop(\"Tangki Septik_Class\", axis=1)\n",
    "sni_tangki_septik_train_y = sni_tangki_septik_train[\"Tangki Septik_Class\"]\n",
    "\n",
    "sni_tangki_septik_test_x = sni_tangki_septik_test.drop(\"Tangki Septik_Class\", axis=1)\n",
    "sni_tangki_septik_test_y = sni_tangki_septik_test[\"Tangki Septik_Class\"]\n",
    "\n",
    "sni_sp_bab_train_x = sni_sp_bab_train.drop(\"Sarana Pembuangan BAB_Class\", axis=1)\n",
    "sni_sp_bab_train_y = sni_sp_bab_train[\"Sarana Pembuangan BAB_Class\"]\n",
    "\n",
    "sni_sp_bab_test_x = sni_sp_bab_test.drop(\"Sarana Pembuangan BAB_Class\", axis=1)\n",
    "sni_sp_bab_test_y = sni_sp_bab_test[\"Sarana Pembuangan BAB_Class\"]\n",
    "\n",
    "sni_iplt_train_x = sni_iplt_train.drop(\"IPLT/IPAL_Class\", axis=1)\n",
    "sni_iplt_train_y = sni_iplt_train[\"IPLT/IPAL_Class\"]\n",
    "\n",
    "sni_iplt_test_x = sni_iplt_test.drop(\"IPLT/IPAL_Class\", axis=1)\n",
    "sni_iplt_test_y = sni_iplt_test[\"IPLT/IPAL_Class\"]\n",
    "\n",
    "sni_drainase_train_x = sni_drainase_train.drop(\"Saluran Drainase_Class\", axis=1)\n",
    "sni_drainase_train_y = sni_drainase_train[\"Saluran Drainase_Class\"]\n",
    "\n",
    "sni_drainase_test_x = sni_drainase_test.drop(\"Saluran Drainase_Class\", axis=1)\n",
    "sni_drainase_test_y = sni_drainase_test[\"Saluran Drainase_Class\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 80000 entries, 75220 to 15795\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   Tangki Septik_Jarak Dari Sumber Air (m)      80000 non-null  float64\n",
      " 1   Tangki Septik_Penggunaan_Berfungsi           80000 non-null  int64  \n",
      " 2   Tangki Septik_Penggunaan_Tidak Berfungsi     80000 non-null  int64  \n",
      " 3   Tangki Septik_Terawat_Tidak                  80000 non-null  int64  \n",
      " 4   Tangki Septik_Terawat_Ya                     80000 non-null  int64  \n",
      " 5   Tangki Septik_Bau Tidak Sedap_Tidak          80000 non-null  int64  \n",
      " 6   Tangki Septik_Bau Tidak Sedap_Ya             80000 non-null  int64  \n",
      " 7   Tangki Septik_Ketercemaran Lingkungan_Tidak  80000 non-null  int64  \n",
      " 8   Tangki Septik_Ketercemaran Lingkungan_Ya     80000 non-null  int64  \n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 6.1 MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 80000 entries, 75220 to 15795\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                                   Non-Null Count  Dtype\n",
      "---  ------                                                   --------------  -----\n",
      " 0   Sarana Pembuangan BAB_Penggunaan_Berfungsi               80000 non-null  int64\n",
      " 1   Sarana Pembuangan BAB_Penggunaan_Tidak Berfungsi         80000 non-null  int64\n",
      " 2   Sarana Pembuangan BAB_Bangunan Terawat_Tidak             80000 non-null  int64\n",
      " 3   Sarana Pembuangan BAB_Bangunan Terawat_Ya                80000 non-null  int64\n",
      " 4   Sarana Pembuangan BAB_Keberadaan Dinding Bangunan_Tidak  80000 non-null  int64\n",
      " 5   Sarana Pembuangan BAB_Keberadaan Dinding Bangunan_Ya     80000 non-null  int64\n",
      " 6   Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu_Tidak   80000 non-null  int64\n",
      " 7   Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu_Ya      80000 non-null  int64\n",
      " 8   Sarana Pembuangan BAB_Penerangan yang Cukup_Tidak        80000 non-null  int64\n",
      " 9   Sarana Pembuangan BAB_Penerangan yang Cukup_Ya           80000 non-null  int64\n",
      " 10  Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa_Tidak  80000 non-null  int64\n",
      " 11  Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa_Ya     80000 non-null  int64\n",
      " 12  Sarana Pembuangan BAB_Terdapat Sarana Air Bersih_Tidak   80000 non-null  int64\n",
      " 13  Sarana Pembuangan BAB_Terdapat Sarana Air Bersih_Ya      80000 non-null  int64\n",
      "dtypes: int64(14)\n",
      "memory usage: 9.2 MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 80000 entries, 75220 to 15795\n",
      "Data columns (total 11 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   IPLT_Jarak Dari Permukiman (km)   80000 non-null  float64\n",
      " 1   IPLT_Penggunaan_Berfungsi         80000 non-null  int64  \n",
      " 2   IPLT_Penggunaan_Tidak Berfungsi   80000 non-null  int64  \n",
      " 3   IPLT_Bangunan Terawat_Tidak       80000 non-null  int64  \n",
      " 4   IPLT_Bangunan Terawat_Ya          80000 non-null  int64  \n",
      " 5   IPLT_Bau Tidak Sedap_Tidak        80000 non-null  int64  \n",
      " 6   IPLT_Bau Tidak Sedap_Ya           80000 non-null  int64  \n",
      " 7   IPLT_Pencemaran Lingkungan_Tidak  80000 non-null  int64  \n",
      " 8   IPLT_Pencemaran Lingkungan_Ya     80000 non-null  int64  \n",
      " 9   IPLT_Air Limbah Berwarna_Tidak    80000 non-null  int64  \n",
      " 10  IPLT_Air Limbah Berwarna_Ya       80000 non-null  int64  \n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 7.3 MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 80000 entries, 75220 to 15795\n",
      "Data columns (total 22 columns):\n",
      " #   Column                                                       Non-Null Count  Dtype\n",
      "---  ------                                                       --------------  -----\n",
      " 0   Saluran Drainase_Hierarki Drainase_Primer                    80000 non-null  int64\n",
      " 1   Saluran Drainase_Hierarki Drainase_Sekunder                  80000 non-null  int64\n",
      " 2   Saluran Drainase_Hierarki Drainase_Tersier                   80000 non-null  int64\n",
      " 3   Saluran Drainase_Jenis Drainase_Terbuka                      80000 non-null  int64\n",
      " 4   Saluran Drainase_Jenis Drainase_Tertutup                     80000 non-null  int64\n",
      " 5   Saluran Drainase_Bentuk Penampang_Persegi                    80000 non-null  int64\n",
      " 6   Saluran Drainase_Bentuk Penampang_Segitiga                   80000 non-null  int64\n",
      " 7   Saluran Drainase_Bentuk Penampang_Setengah Lingkaran         80000 non-null  int64\n",
      " 8   Saluran Drainase_Bentuk Penampang_Trapesiun                  80000 non-null  int64\n",
      " 9   Saluran Drainase_Perkerasan Tepi Drainase_Batuan             80000 non-null  int64\n",
      " 10  Saluran Drainase_Perkerasan Tepi Drainase_Kerikil Halus      80000 non-null  int64\n",
      " 11  Saluran Drainase_Perkerasan Tepi Drainase_Lempung Kepasiran  80000 non-null  int64\n",
      " 12  Saluran Drainase_Perkerasan Tepi Drainase_Pasir Halus        80000 non-null  int64\n",
      " 13  Saluran Drainase_Perkerasan Tepi Drainase_Tanah              80000 non-null  int64\n",
      " 14  Saluran Drainase_Kondisi Drainase_Terawat                    80000 non-null  int64\n",
      " 15  Saluran Drainase_Kondisi Drainase_Tidak Terawat              80000 non-null  int64\n",
      " 16  Saluran Drainase_Bau Tidak Sedap_Tidak                       80000 non-null  int64\n",
      " 17  Saluran Drainase_Bau Tidak Sedap_Ya                          80000 non-null  int64\n",
      " 18  Saluran Drainase_Sedimentasi Drainase_Eceng Gondok           80000 non-null  int64\n",
      " 19  Saluran Drainase_Sedimentasi Drainase_Sampah                 80000 non-null  int64\n",
      " 20  Saluran Drainase_Sedimentasi Drainase_Tanah                  80000 non-null  int64\n",
      " 21  Saluran Drainase_Sedimentasi Drainase_Tidak Ada              80000 non-null  int64\n",
      "dtypes: int64(22)\n",
      "memory usage: 14.0 MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20000 entries, 75721 to 42410\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   Tangki Septik_Jarak Dari Sumber Air (m)      20000 non-null  float64\n",
      " 1   Tangki Septik_Penggunaan_Berfungsi           20000 non-null  int64  \n",
      " 2   Tangki Septik_Penggunaan_Tidak Berfungsi     20000 non-null  int64  \n",
      " 3   Tangki Septik_Terawat_Tidak                  20000 non-null  int64  \n",
      " 4   Tangki Septik_Terawat_Ya                     20000 non-null  int64  \n",
      " 5   Tangki Septik_Bau Tidak Sedap_Tidak          20000 non-null  int64  \n",
      " 6   Tangki Septik_Bau Tidak Sedap_Ya             20000 non-null  int64  \n",
      " 7   Tangki Septik_Ketercemaran Lingkungan_Tidak  20000 non-null  int64  \n",
      " 8   Tangki Septik_Ketercemaran Lingkungan_Ya     20000 non-null  int64  \n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 1.5 MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20000 entries, 75721 to 42410\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                                   Non-Null Count  Dtype\n",
      "---  ------                                                   --------------  -----\n",
      " 0   Sarana Pembuangan BAB_Penggunaan_Berfungsi               20000 non-null  int64\n",
      " 1   Sarana Pembuangan BAB_Penggunaan_Tidak Berfungsi         20000 non-null  int64\n",
      " 2   Sarana Pembuangan BAB_Bangunan Terawat_Tidak             20000 non-null  int64\n",
      " 3   Sarana Pembuangan BAB_Bangunan Terawat_Ya                20000 non-null  int64\n",
      " 4   Sarana Pembuangan BAB_Keberadaan Dinding Bangunan_Tidak  20000 non-null  int64\n",
      " 5   Sarana Pembuangan BAB_Keberadaan Dinding Bangunan_Ya     20000 non-null  int64\n",
      " 6   Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu_Tidak   20000 non-null  int64\n",
      " 7   Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu_Ya      20000 non-null  int64\n",
      " 8   Sarana Pembuangan BAB_Penerangan yang Cukup_Tidak        20000 non-null  int64\n",
      " 9   Sarana Pembuangan BAB_Penerangan yang Cukup_Ya           20000 non-null  int64\n",
      " 10  Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa_Tidak  20000 non-null  int64\n",
      " 11  Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa_Ya     20000 non-null  int64\n",
      " 12  Sarana Pembuangan BAB_Terdapat Sarana Air Bersih_Tidak   20000 non-null  int64\n",
      " 13  Sarana Pembuangan BAB_Terdapat Sarana Air Bersih_Ya      20000 non-null  int64\n",
      "dtypes: int64(14)\n",
      "memory usage: 2.3 MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20000 entries, 75721 to 42410\n",
      "Data columns (total 11 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   IPLT_Jarak Dari Permukiman (km)   20000 non-null  float64\n",
      " 1   IPLT_Penggunaan_Berfungsi         20000 non-null  int64  \n",
      " 2   IPLT_Penggunaan_Tidak Berfungsi   20000 non-null  int64  \n",
      " 3   IPLT_Bangunan Terawat_Tidak       20000 non-null  int64  \n",
      " 4   IPLT_Bangunan Terawat_Ya          20000 non-null  int64  \n",
      " 5   IPLT_Bau Tidak Sedap_Tidak        20000 non-null  int64  \n",
      " 6   IPLT_Bau Tidak Sedap_Ya           20000 non-null  int64  \n",
      " 7   IPLT_Pencemaran Lingkungan_Tidak  20000 non-null  int64  \n",
      " 8   IPLT_Pencemaran Lingkungan_Ya     20000 non-null  int64  \n",
      " 9   IPLT_Air Limbah Berwarna_Tidak    20000 non-null  int64  \n",
      " 10  IPLT_Air Limbah Berwarna_Ya       20000 non-null  int64  \n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20000 entries, 75721 to 42410\n",
      "Data columns (total 22 columns):\n",
      " #   Column                                                       Non-Null Count  Dtype\n",
      "---  ------                                                       --------------  -----\n",
      " 0   Saluran Drainase_Hierarki Drainase_Primer                    20000 non-null  int64\n",
      " 1   Saluran Drainase_Hierarki Drainase_Sekunder                  20000 non-null  int64\n",
      " 2   Saluran Drainase_Hierarki Drainase_Tersier                   20000 non-null  int64\n",
      " 3   Saluran Drainase_Jenis Drainase_Terbuka                      20000 non-null  int64\n",
      " 4   Saluran Drainase_Jenis Drainase_Tertutup                     20000 non-null  int64\n",
      " 5   Saluran Drainase_Bentuk Penampang_Persegi                    20000 non-null  int64\n",
      " 6   Saluran Drainase_Bentuk Penampang_Segitiga                   20000 non-null  int64\n",
      " 7   Saluran Drainase_Bentuk Penampang_Setengah Lingkaran         20000 non-null  int64\n",
      " 8   Saluran Drainase_Bentuk Penampang_Trapesiun                  20000 non-null  int64\n",
      " 9   Saluran Drainase_Perkerasan Tepi Drainase_Batuan             20000 non-null  int64\n",
      " 10  Saluran Drainase_Perkerasan Tepi Drainase_Kerikil Halus      20000 non-null  int64\n",
      " 11  Saluran Drainase_Perkerasan Tepi Drainase_Lempung Kepasiran  20000 non-null  int64\n",
      " 12  Saluran Drainase_Perkerasan Tepi Drainase_Pasir Halus        20000 non-null  int64\n",
      " 13  Saluran Drainase_Perkerasan Tepi Drainase_Tanah              20000 non-null  int64\n",
      " 14  Saluran Drainase_Kondisi Drainase_Terawat                    20000 non-null  int64\n",
      " 15  Saluran Drainase_Kondisi Drainase_Tidak Terawat              20000 non-null  int64\n",
      " 16  Saluran Drainase_Bau Tidak Sedap_Tidak                       20000 non-null  int64\n",
      " 17  Saluran Drainase_Bau Tidak Sedap_Ya                          20000 non-null  int64\n",
      " 18  Saluran Drainase_Sedimentasi Drainase_Eceng Gondok           20000 non-null  int64\n",
      " 19  Saluran Drainase_Sedimentasi Drainase_Sampah                 20000 non-null  int64\n",
      " 20  Saluran Drainase_Sedimentasi Drainase_Tanah                  20000 non-null  int64\n",
      " 21  Saluran Drainase_Sedimentasi Drainase_Tidak Ada              20000 non-null  int64\n",
      "dtypes: int64(22)\n",
      "memory usage: 3.5 MB\n",
      "None\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lastly, we need to encode the categorical data\n",
    "# We do this after splitting the data because we don't want to accidentally leak the feature data to the target class\n",
    "\n",
    "# First, retrieve the categorical columns and set them as categorical\n",
    "feature_database = [sni_tangki_septik_train_x, sni_sp_bab_train_x, sni_iplt_train_x, sni_drainase_train_x, sni_tangki_septik_test_x, sni_sp_bab_test_x, sni_iplt_test_x, sni_drainase_test_x]\n",
    "\n",
    "for data_idx in range(len(feature_database)):\n",
    "    categorical_columns = []\n",
    "    data = feature_database[data_idx]\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':\n",
    "            categorical_columns.append(col)\n",
    "            data.loc[:, col] = data[col].astype('category')\n",
    "    \n",
    "    temp = pd.get_dummies(data, columns=categorical_columns, dtype='int64')\n",
    "    data = temp.reindex(columns=categorical_columns + temp.columns.tolist())\n",
    "    data = data.drop(categorical_columns, axis=1)\n",
    "    \n",
    "    feature_database[data_idx] = data\n",
    "    \n",
    "    print(data.info())\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    \n",
    "# Re-set the database values\n",
    "sni_tangki_septik_train_x = feature_database[0]\n",
    "sni_sp_bab_train_x = feature_database[1]\n",
    "sni_iplt_train_x = feature_database[2]\n",
    "sni_drainase_train_x = feature_database[3]\n",
    "sni_tangki_septik_test_x = feature_database[4]\n",
    "sni_sp_bab_test_x = feature_database[5]\n",
    "sni_iplt_test_x = feature_database[6]\n",
    "sni_drainase_test_x = feature_database[7]\n",
    "\n",
    "# We need to make sure the order of columns are the same for both training and testing data\n",
    "if sni_tangki_septik_train_x.columns.tolist() != sni_tangki_septik_test_x.columns.tolist():\n",
    "    print(\"Columns are not the same for both training and testing data for Tangki Septik\")\n",
    "if sni_sp_bab_train_x.columns.tolist() != sni_sp_bab_test_x.columns.tolist():\n",
    "    print(\"Columns are not the same for both training and testing data for Sarana Pembuangan BAB\")\n",
    "if sni_iplt_train_x.columns.tolist() != sni_iplt_test_x.columns.tolist():\n",
    "    print(\"Columns are not the same for both training and testing data for IPLT/IPAL\")\n",
    "if sni_drainase_train_x.columns.tolist() != sni_drainase_test_x.columns.tolist():\n",
    "    print(\"Columns are not the same for both training and testing data for Saluran Drainase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Currently processing: Tangki Septik_Class\n",
      "Tangki Septik_Class\n",
      "0    68563\n",
      "1    11437\n",
      "Name: count, dtype: int64\n",
      "75220    0\n",
      "48955    0\n",
      "44966    0\n",
      "13568    0\n",
      "92727    0\n",
      "Name: Tangki Septik_Class, dtype: object\n",
      "------------------------------------------------------------------\n",
      "Currently processing: Sarana Pembuangan BAB_Class\n",
      "Sarana Pembuangan BAB_Class\n",
      "0    79463\n",
      "1      537\n",
      "Name: count, dtype: int64\n",
      "75220    0\n",
      "48955    0\n",
      "44966    0\n",
      "13568    0\n",
      "92727    0\n",
      "Name: Sarana Pembuangan BAB_Class, dtype: object\n",
      "------------------------------------------------------------------\n",
      "Currently processing: IPLT/IPAL_Class\n",
      "IPLT/IPAL_Class\n",
      "0    62411\n",
      "1    17589\n",
      "Name: count, dtype: int64\n",
      "75220    0\n",
      "48955    0\n",
      "44966    0\n",
      "13568    1\n",
      "92727    0\n",
      "Name: IPLT/IPAL_Class, dtype: object\n",
      "------------------------------------------------------------------\n",
      "Currently processing: Saluran Drainase_Class\n",
      "Saluran Drainase_Class\n",
      "1    42679\n",
      "0    37321\n",
      "Name: count, dtype: int64\n",
      "75220    0\n",
      "48955    0\n",
      "44966    1\n",
      "13568    0\n",
      "92727    0\n",
      "Name: Saluran Drainase_Class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Lastly, we need to check on the class imbalance.\n",
    "# We can do this by checking the percentage of each class in the target class\n",
    "# If the data is imbalanced, we need to recombine the x and y data, and then perform undersampling/oversampling based on the minority/majority class\n",
    "class_columns = [\"Tangki Septik_Class\", \"Sarana Pembuangan BAB_Class\", \"IPLT/IPAL_Class\", \"Saluran Drainase_Class\"]\n",
    "class_database = [sni_tangki_septik_train_y, sni_sp_bab_train_y, sni_iplt_train_y, sni_drainase_train_y]\n",
    "\n",
    "# First, recast the class data to int64\n",
    "for database in class_database:\n",
    "    database = database.astype(\"int64\")\n",
    "\n",
    "# Count the number of each class (it's binary, only 1 or 0)\n",
    "for data_idx in range(len(class_database)):\n",
    "    data = class_database[data_idx]\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(\"Currently processing: \" + class_columns[data_idx])\n",
    "    print(data.value_counts())\n",
    "    print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11437\n"
     ]
    }
   ],
   "source": [
    "# We hope to see a 50:50 split, 40:60 split, or 20:80 split. If not, we need to perform undersampling/oversampling\n",
    "# That said, we need to perform undersampling of \"0\" class to data \"Tangki Septik\" and \"Sistem Pembuangan BAB\"\n",
    "\n",
    "# So, we need to combine the x and y data first\n",
    "# We will process \"Tangki Septik\" data first\n",
    "# Concat the database and then split it based on the majority class and minority class\n",
    "sni_tangki_septik_train = pd.concat([sni_tangki_septik_train_x, sni_tangki_septik_train_y], axis=1)\n",
    "\n",
    "minority_class = sni_tangki_septik_train[sni_tangki_septik_train[\"Tangki Septik_Class\"] == \"1\"]\n",
    "majority_class = sni_tangki_septik_train[sni_tangki_septik_train[\"Tangki Septik_Class\"] == \"0\"]\n",
    "\n",
    "minority_size = len(minority_class)\n",
    "print(minority_size)\n",
    "\n",
    "undersampled_majority_class = majority_class.sample(n=round(minority_size * 1.65), random_state=42) # To make the split 60:40\n",
    "\n",
    "sni_tangki_septik_train = pd.concat([minority_class, undersampled_majority_class], axis=0)\n",
    "\n",
    "# print(sni_tangki_septik_train.info())\n",
    "# print(sni_tangki_septik_train[\"Tangki Septik_Class\"].value_counts())\n",
    "\n",
    "# Then split it again as x and y\n",
    "sni_tangki_septik_train_x = sni_tangki_septik_train.drop(\"Tangki Septik_Class\", axis=1)\n",
    "sni_tangki_septik_train_y = sni_tangki_septik_train[\"Tangki Septik_Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1423 entries, 51435 to 83472\n",
      "Data columns (total 15 columns):\n",
      " #   Column                                                   Non-Null Count  Dtype \n",
      "---  ------                                                   --------------  ----- \n",
      " 0   Sarana Pembuangan BAB_Penggunaan_Berfungsi               1423 non-null   int64 \n",
      " 1   Sarana Pembuangan BAB_Penggunaan_Tidak Berfungsi         1423 non-null   int64 \n",
      " 2   Sarana Pembuangan BAB_Bangunan Terawat_Tidak             1423 non-null   int64 \n",
      " 3   Sarana Pembuangan BAB_Bangunan Terawat_Ya                1423 non-null   int64 \n",
      " 4   Sarana Pembuangan BAB_Keberadaan Dinding Bangunan_Tidak  1423 non-null   int64 \n",
      " 5   Sarana Pembuangan BAB_Keberadaan Dinding Bangunan_Ya     1423 non-null   int64 \n",
      " 6   Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu_Tidak   1423 non-null   int64 \n",
      " 7   Sarana Pembuangan BAB_Keberadaan Ventilasi Pintu_Ya      1423 non-null   int64 \n",
      " 8   Sarana Pembuangan BAB_Penerangan yang Cukup_Tidak        1423 non-null   int64 \n",
      " 9   Sarana Pembuangan BAB_Penerangan yang Cukup_Ya           1423 non-null   int64 \n",
      " 10  Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa_Tidak  1423 non-null   int64 \n",
      " 11  Sarana Pembuangan BAB_Terdapat Kloset Leher Angsa_Ya     1423 non-null   int64 \n",
      " 12  Sarana Pembuangan BAB_Terdapat Sarana Air Bersih_Tidak   1423 non-null   int64 \n",
      " 13  Sarana Pembuangan BAB_Terdapat Sarana Air Bersih_Ya      1423 non-null   int64 \n",
      " 14  Sarana Pembuangan BAB_Class                              1423 non-null   object\n",
      "dtypes: int64(14), object(1)\n",
      "memory usage: 177.9+ KB\n",
      "None\n",
      "Sarana Pembuangan BAB_Class\n",
      "0    886\n",
      "1    537\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Do the same for \"Sistem Pembuangan BAB\" data first\n",
    "# Concat the database and then split it based on the majority class and minority class\n",
    "sni_sp_bab_train = pd.concat([sni_sp_bab_train_x, sni_sp_bab_train_y], axis=1)\n",
    "\n",
    "minority_class = sni_sp_bab_train[sni_sp_bab_train[\"Sarana Pembuangan BAB_Class\"] == \"1\"]\n",
    "majority_class = sni_sp_bab_train[sni_sp_bab_train[\"Sarana Pembuangan BAB_Class\"] == \"0\"]\n",
    "\n",
    "minority_size = len(minority_class)\n",
    "print(minority_size)\n",
    "\n",
    "undersampled_majority_class = majority_class.sample(n=round(minority_size * 1.65), random_state=42) # To make the split 60:40\n",
    "\n",
    "sni_sp_bab_train = pd.concat([minority_class, undersampled_majority_class], axis=0)\n",
    "\n",
    "print(sni_sp_bab_train.info())\n",
    "print(sni_sp_bab_train[\"Sarana Pembuangan BAB_Class\"].value_counts())\n",
    "\n",
    "sni_sp_bab_train_x = sni_sp_bab_train.drop(\"Sarana Pembuangan BAB_Class\", axis=1)\n",
    "sni_sp_bab_train_y = sni_sp_bab_train[\"Sarana Pembuangan BAB_Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploratory Data Analysis and Data Preprocessing completed\n",
    "# We will not use PCA or any other feature selection methods as the number of features are not that many\n",
    "# Next, we will create machine learning models for each of the data.\n",
    "# For this assignment, we will create in total 12 models, 3 for each data\n",
    "\n",
    "# First model is Logistic Regression.\n",
    "# Reason for choosing this model is because it is simple and perfect for binary classification (1 or 0)\n",
    "# The domain knowledge source also said that the data is linearly separable, so this model is perfect for this data\n",
    "# By data, I mean all of the data, not just one of them (\"Tangki Septik\", \"Sistem Pembuangan BAB\", \"Saluran Drainase\", and \"IPLT/IPAL\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "model_tangki_septik = LogisticRegression()\n",
    "model_tangki_septik.fit(sni_tangki_septik_train_x, sni_tangki_septik_train_y)\n",
    "\n",
    "model_sp_bab = LogisticRegression()\n",
    "model_sp_bab.fit(sni_sp_bab_train_x, sni_sp_bab_train_y)\n",
    "\n",
    "model_drainase = LogisticRegression()\n",
    "model_drainase.fit(sni_drainase_train_x, sni_drainase_train_y)\n",
    "\n",
    "model_iplt = LogisticRegression()\n",
    "model_iplt.fit(sni_iplt_train_x, sni_iplt_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tangki Septik Logistic Regression Evaluation Results\n",
      "Accuracy:  0.19925\n",
      "Confusion Matrix: \n",
      " [[ 1128 16015]\n",
      " [    0  2857]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.12     17143\n",
      "           1       0.15      1.00      0.26      2857\n",
      "\n",
      "    accuracy                           0.20     20000\n",
      "   macro avg       0.58      0.53      0.19     20000\n",
      "weighted avg       0.88      0.20      0.14     20000\n",
      "\n",
      "---------------------------------------------\n",
      "Sistem Pembuangan BAB Logistic Regression Evaluation Results\n",
      "Accuracy:  0.99185\n",
      "Confusion Matrix: \n",
      " [[19709   163]\n",
      " [    0   128]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19872\n",
      "           1       0.44      1.00      0.61       128\n",
      "\n",
      "    accuracy                           0.99     20000\n",
      "   macro avg       0.72      1.00      0.80     20000\n",
      "weighted avg       1.00      0.99      0.99     20000\n",
      "\n",
      "---------------------------------------------\n",
      "Saluran Drainase Logistic Regression Evaluation Results\n",
      "Accuracy:  1.0\n",
      "Confusion Matrix: \n",
      " [[ 9395     0]\n",
      " [    0 10605]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9395\n",
      "           1       1.00      1.00      1.00     10605\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "---------------------------------------------\n",
      "IPLT/IPAL Logistic Regression Evaluation Results\n",
      "Accuracy:  0.3449\n",
      "Confusion Matrix: \n",
      " [[ 2522 13102]\n",
      " [    0  4376]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.16      0.28     15624\n",
      "           1       0.25      1.00      0.40      4376\n",
      "\n",
      "    accuracy                           0.34     20000\n",
      "   macro avg       0.63      0.58      0.34     20000\n",
      "weighted avg       0.84      0.34      0.30     20000\n",
      "\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now, we need to test the model using the test data and then evaluate the models\n",
    "\n",
    "# For \"Tangki Septik\" data\n",
    "sni_tangki_septik_test_y_pred = model_tangki_septik.predict(sni_tangki_septik_test_x)\n",
    "accuracy = accuracy_score(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "class_report = classification_report(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "\n",
    "print(\"Tangki Septik Logistic Regression Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"Sistem Pembuangan BAB\" data\n",
    "sni_sp_bab_test_y_pred = model_sp_bab.predict(sni_sp_bab_test_x)\n",
    "accuracy = accuracy_score(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "class_report = classification_report(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "\n",
    "print(\"Sistem Pembuangan BAB Logistic Regression Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"Saluran Drainase\" data\n",
    "sni_drainase_test_y_pred = model_drainase.predict(sni_drainase_test_x)\n",
    "accuracy = accuracy_score(sni_drainase_test_y, sni_drainase_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_drainase_test_y, sni_drainase_test_y_pred)\n",
    "class_report = classification_report(sni_drainase_test_y, sni_drainase_test_y_pred)\n",
    "\n",
    "print(\"Saluran Drainase Logistic Regression Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"IPLT/IPAL\" data\n",
    "sni_iplt_test_y_pred = model_iplt.predict(sni_iplt_test_x)\n",
    "accuracy = accuracy_score(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "class_report = classification_report(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "\n",
    "print(\"IPLT/IPAL Logistic Regression Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gede Prasidha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gede Prasidha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, solver='liblinear')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the results above, we can see that for \"Saluran Drainase\" data, the model is perfect with 100% accuracy\n",
    "# Therefore, we can assume that the data is 100% linearly separable and hyperparameter tuning is not needed\n",
    "\n",
    "# Next, we need to use hyperparameter tuning for the other 3 models as it is still not quite there yet\n",
    "# We will use GridSearchCV for this task\n",
    "# We will also use 5-fold cross validation to make sure that the model is not overfitting\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# For \"Tangki Septik\" data\n",
    "grid_search = GridSearchCV(estimator=model_tangki_septik, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(sni_tangki_septik_train_x, sni_tangki_septik_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model_tangki_septik = LogisticRegression(**best_params)\n",
    "best_model_tangki_septik.fit(sni_tangki_septik_train_x, sni_tangki_septik_train_y)\n",
    "\n",
    "# For \"Sistem Pembuangan BAB\" data\n",
    "grid_search = GridSearchCV(estimator=model_sp_bab, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(sni_sp_bab_train_x, sni_sp_bab_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model_sp_bab = LogisticRegression(**best_params)\n",
    "best_model_sp_bab.fit(sni_sp_bab_train_x, sni_sp_bab_train_y)\n",
    "\n",
    "# For \"IPLT/IPAL\" data\n",
    "grid_search = GridSearchCV(estimator=model_iplt, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(sni_iplt_train_x, sni_iplt_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model_iplt = LogisticRegression(**best_params)\n",
    "best_model_iplt.fit(sni_iplt_train_x, sni_iplt_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tangki Septik Logistic Regression with Hyperparameter Tuning Evaluation Results\n",
      "Accuracy:  0.18405\n",
      "Confusion Matrix: \n",
      " [[  824 16319]\n",
      " [    0  2857]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.09     17143\n",
      "           1       0.15      1.00      0.26      2857\n",
      "\n",
      "    accuracy                           0.18     20000\n",
      "   macro avg       0.57      0.52      0.18     20000\n",
      "weighted avg       0.88      0.18      0.12     20000\n",
      "\n",
      "---------------------------------------------\n",
      "Sistem Pembuangan BAB Logistic Regression with Hyperparameter Tuning Evaluation Results\n",
      "Accuracy:  0.99625\n",
      "Confusion Matrix: \n",
      " [[19797    75]\n",
      " [    0   128]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19872\n",
      "           1       0.63      1.00      0.77       128\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.82      1.00      0.89     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "---------------------------------------------\n",
      "IPLT/IPAL Logistic Regression with Hyperparameter Tuning Evaluation Results\n",
      "Accuracy:  0.3298\n",
      "Confusion Matrix: \n",
      " [[ 2220 13404]\n",
      " [    0  4376]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25     15624\n",
      "           1       0.25      1.00      0.40      4376\n",
      "\n",
      "    accuracy                           0.33     20000\n",
      "   macro avg       0.62      0.57      0.32     20000\n",
      "weighted avg       0.84      0.33      0.28     20000\n",
      "\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now we will re-evaluate the models using the test data just like before\n",
    "# For \"Tangki Septik\" data\n",
    "sni_tangki_septik_test_y_pred = best_model_tangki_septik.predict(sni_tangki_septik_test_x)\n",
    "accuracy = accuracy_score(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "class_report = classification_report(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "\n",
    "print(\"Tangki Septik Logistic Regression with Hyperparameter Tuning Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"Sistem Pembuangan BAB\" data\n",
    "sni_sp_bab_test_y_pred = best_model_sp_bab.predict(sni_sp_bab_test_x)\n",
    "accuracy = accuracy_score(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "class_report = classification_report(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "\n",
    "print(\"Sistem Pembuangan BAB Logistic Regression with Hyperparameter Tuning Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"IPLT/IPAL\" data\n",
    "sni_iplt_test_y_pred = best_model_iplt.predict(sni_iplt_test_x)\n",
    "accuracy = accuracy_score(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "class_report = classification_report(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "\n",
    "print(\"IPLT/IPAL Logistic Regression with Hyperparameter Tuning Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After parameter tuning, we can see that the accuracy for the 3 models have mixed results\n",
    "# For the \"Sistem Pembuangan BAB\" data, the accuracy has increased from 0.99185 to 0.99625\n",
    "# While for the \"Tangki Septik\" data, the accuracy has decreased to 0.18405 from 0.19925\n",
    "# The same goes to \"IPLT/IPAL\" data, the accuracy has decreased to 0.3298 from 0.3449\n",
    "\n",
    "# We will now attempt to use other classification models to see if we can get better results\n",
    "# We will use K-Nearest Neighbors (KNN) for the second model\n",
    "# Reason is that KNN is a non-parametric model and it is also a lazy learner\n",
    "# This means that it does not make any assumptions about the data distribution and it does not learn anything from the training data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# For \"Tangki Septik\" data\n",
    "knn_tangki_septik = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_tangki_septik.fit(sni_tangki_septik_train_x, sni_tangki_septik_train_y)\n",
    "\n",
    "# For \"Sistem Pembuangan BAB\" data\n",
    "knn_sp_bab = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_sp_bab.fit(sni_sp_bab_train_x, sni_sp_bab_train_y)\n",
    "\n",
    "# For \"IPLT/IPAL\" data\n",
    "knn_iplt = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_iplt.fit(sni_iplt_train_x, sni_iplt_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tangki Septik KNN Evaluation Results\n",
      "Accuracy:  0.958\n",
      "Confusion Matrix: \n",
      " [[16303   840]\n",
      " [    0  2857]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     17143\n",
      "           1       0.77      1.00      0.87      2857\n",
      "\n",
      "    accuracy                           0.96     20000\n",
      "   macro avg       0.89      0.98      0.92     20000\n",
      "weighted avg       0.97      0.96      0.96     20000\n",
      "\n",
      "---------------------------------------------\n",
      "Sistem Pembuangan BAB KNN Evaluation Results\n",
      "Accuracy:  0.98005\n",
      "Confusion Matrix: \n",
      " [[19473   399]\n",
      " [    0   128]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19872\n",
      "           1       0.24      1.00      0.39       128\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.62      0.99      0.69     20000\n",
      "weighted avg       1.00      0.98      0.99     20000\n",
      "\n",
      "---------------------------------------------\n",
      "IPLT/IPAL KNN Evaluation Results\n",
      "Accuracy:  0.94345\n",
      "Confusion Matrix: \n",
      " [[14503  1121]\n",
      " [   10  4366]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     15624\n",
      "           1       0.80      1.00      0.89      4376\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.90      0.96      0.92     20000\n",
      "weighted avg       0.95      0.94      0.95     20000\n",
      "\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now, we need to test the model using the test data and then evaluate the models\n",
    "\n",
    "# For \"Tangki Septik\" data\n",
    "sni_tangki_septik_test_y_pred = knn_tangki_septik.predict(sni_tangki_septik_test_x)\n",
    "accuracy = accuracy_score(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "class_report = classification_report(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "\n",
    "print(\"Tangki Septik KNN Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"Sistem Pembuangan BAB\" data\n",
    "sni_sp_bab_test_y_pred = knn_sp_bab.predict(sni_sp_bab_test_x)\n",
    "accuracy = accuracy_score(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "class_report = classification_report(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "\n",
    "print(\"Sistem Pembuangan BAB KNN Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"IPLT/IPAL\" data\n",
    "sni_iplt_test_y_pred = knn_iplt.predict(sni_iplt_test_x)\n",
    "accuracy = accuracy_score(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "class_report = classification_report(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "\n",
    "print(\"IPLT/IPAL KNN Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see from the results above that it's inverted to the results from the Logistic Regression model\n",
    "# Both models for \"Tangki Septik\" and \"IPLT/IPAL\" have increased marginally in accuracy\n",
    "# While the model for \"Sistem Pembuangan BAB\" has decreased in accuracy\n",
    "\n",
    "# Now, we will perform hyperparameter tuning for the KNN model. Again we will use GridSearchCV since there's not many combinations to try\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11, 13, 15]}\n",
    "\n",
    "# For \"Tangki Septik\" data\n",
    "grid_search = GridSearchCV(estimator=knn_tangki_septik, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(sni_tangki_septik_train_x, sni_tangki_septik_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_knn_tangki_septik = grid_search.best_estimator_\n",
    "best_knn_tangki_septik.fit(sni_tangki_septik_train_x, sni_tangki_septik_train_y)\n",
    "\n",
    "# For \"Sistem Pembuangan BAB\" data\n",
    "grid_search = GridSearchCV(estimator=knn_sp_bab, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(sni_sp_bab_train_x, sni_sp_bab_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_knn_sp_bab = grid_search.best_estimator_\n",
    "best_knn_sp_bab.fit(sni_sp_bab_train_x, sni_sp_bab_train_y)\n",
    "\n",
    "# For \"IPLT/IPAL\" data\n",
    "grid_search = GridSearchCV(estimator=knn_iplt, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(sni_iplt_train_x, sni_iplt_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_knn_iplt = grid_search.best_estimator_\n",
    "best_knn_iplt.fit(sni_iplt_train_x, sni_iplt_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tangki Septik K-Nearest Neighbor Classifier with Hyperparameter Tuning Evaluation Results\n",
      "Accuracy:  0.96025\n",
      "Confusion Matrix: \n",
      " [[16348   795]\n",
      " [    0  2857]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98     17143\n",
      "           1       0.78      1.00      0.88      2857\n",
      "\n",
      "    accuracy                           0.96     20000\n",
      "   macro avg       0.89      0.98      0.93     20000\n",
      "weighted avg       0.97      0.96      0.96     20000\n",
      "\n",
      "---------------------------------------------\n",
      "Sistem Pembuangan BAB K-Nearest Neighbor Classifier with Hyperparameter Tuning Evaluation Results\n",
      "Accuracy:  0.98575\n",
      "Confusion Matrix: \n",
      " [[19587   285]\n",
      " [    0   128]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     19872\n",
      "           1       0.31      1.00      0.47       128\n",
      "\n",
      "    accuracy                           0.99     20000\n",
      "   macro avg       0.65      0.99      0.73     20000\n",
      "weighted avg       1.00      0.99      0.99     20000\n",
      "\n",
      "---------------------------------------------\n",
      "IPLT/IPAL K-Nearest Neighbor Classifier with Hyperparameter Tuning Evaluation Results\n",
      "Accuracy:  0.94345\n",
      "Confusion Matrix: \n",
      " [[14503  1121]\n",
      " [   10  4366]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     15624\n",
      "           1       0.80      1.00      0.89      4376\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.90      0.96      0.92     20000\n",
      "weighted avg       0.95      0.94      0.95     20000\n",
      "\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now we will re-evaluate the models using the test data just like before\n",
    "# For \"Tangki Septik\" data\n",
    "sni_tangki_septik_test_y_pred = best_knn_tangki_septik.predict(sni_tangki_septik_test_x)\n",
    "accuracy = accuracy_score(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "class_report = classification_report(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "\n",
    "print(\"Tangki Septik K-Nearest Neighbor Classifier with Hyperparameter Tuning Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"Sistem Pembuangan BAB\" data\n",
    "sni_sp_bab_test_y_pred = best_knn_sp_bab.predict(sni_sp_bab_test_x)\n",
    "accuracy = accuracy_score(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "class_report = classification_report(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "\n",
    "print(\"Sistem Pembuangan BAB K-Nearest Neighbor Classifier with Hyperparameter Tuning Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"IPLT/IPAL\" data\n",
    "sni_iplt_test_y_pred = best_knn_iplt.predict(sni_iplt_test_x)\n",
    "accuracy = accuracy_score(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "class_report = classification_report(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "\n",
    "print(\"IPLT/IPAL K-Nearest Neighbor Classifier with Hyperparameter Tuning Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall, there is a slight increase in accuracy for all models except for the \"IPLT/IPAL\" model which shows no change\n",
    "\n",
    "# Moving on to the next model, we will use the Random Forest Classifier\n",
    "# Reason for choosing this method is because comparing the previous 2 methods, at first it is thought that the data is linearly separable\n",
    "# Which is most likely that it is not (except for \"Saluran Drainase\" data) since Logistic Regression is outperformed by KNN\n",
    "# So the hypothesis is that the data is non-linearly separable and that there's no independence of features, which is why we will use Random Forest Classifier\n",
    "# Also, this classifier is also of ensemble method, which means it will combine multiple decision trees for a better accuracy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For \"Tangki Septik\" data\n",
    "rf_tangki_septik = RandomForestClassifier()\n",
    "rf_tangki_septik.fit(sni_tangki_septik_train_x, sni_tangki_septik_train_y)\n",
    "\n",
    "# For \"Sistem Pembuangan BAB\" data\n",
    "rf_sp_bab = RandomForestClassifier()\n",
    "rf_sp_bab.fit(sni_sp_bab_train_x, sni_sp_bab_train_y)\n",
    "\n",
    "# For \"IPLT/IPAL\" data\n",
    "rf_iplt = RandomForestClassifier()\n",
    "rf_iplt.fit(sni_iplt_train_x, sni_iplt_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tangki Septik Random Forest Classifier Evaluation Results\n",
      "Accuracy:  0.98115\n",
      "Confusion Matrix: \n",
      " [[16766   377]\n",
      " [    0  2857]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     17143\n",
      "           1       0.88      1.00      0.94      2857\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.94      0.99      0.96     20000\n",
      "weighted avg       0.98      0.98      0.98     20000\n",
      "\n",
      "---------------------------------------------\n",
      "Sistem Pembuangan BAB Random Forest Classifier Evaluation Results\n",
      "Accuracy:  0.9979\n",
      "Confusion Matrix: \n",
      " [[19830    42]\n",
      " [    0   128]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19872\n",
      "           1       0.75      1.00      0.86       128\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.88      1.00      0.93     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "---------------------------------------------\n",
      "IPLT/IPAL Random Forest Classifier Evaluation Results\n",
      "Accuracy:  0.945\n",
      "Confusion Matrix: \n",
      " [[14524  1100]\n",
      " [    0  4376]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     15624\n",
      "           1       0.80      1.00      0.89      4376\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.90      0.96      0.93     20000\n",
      "weighted avg       0.96      0.94      0.95     20000\n",
      "\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now, we need to test the model using the test data and then evaluate the models\n",
    "\n",
    "# For \"Tangki Septik\" data\n",
    "sni_tangki_septik_test_y_pred = rf_tangki_septik.predict(sni_tangki_septik_test_x)\n",
    "accuracy = accuracy_score(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "class_report = classification_report(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "\n",
    "print(\"Tangki Septik Random Forest Classifier Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"Sistem Pembuangan BAB\" data\n",
    "sni_sp_bab_test_y_pred = rf_sp_bab.predict(sni_sp_bab_test_x)\n",
    "accuracy = accuracy_score(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "class_report = classification_report(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "\n",
    "print(\"Sistem Pembuangan BAB Random Forest Classifier Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"IPLT/IPAL\" data\n",
    "sni_iplt_test_y_pred = rf_iplt.predict(sni_iplt_test_x)\n",
    "accuracy = accuracy_score(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "class_report = classification_report(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "\n",
    "print(\"IPLT/IPAL Random Forest Classifier Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(min_samples_split=5, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_split=5, n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(min_samples_split=5, n_estimators=200)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see from the results above that it has really good performance for all models for all data compared to the previous two methods\n",
    "\n",
    "# Now, we will perform hyperparameter tuning for the KNN model. Again we will use GridSearchCV since there's not many combinations to try\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# For \"Tangki Septik\" data\n",
    "grid_search = GridSearchCV(estimator=rf_tangki_septik, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(sni_tangki_septik_train_x, sni_tangki_septik_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score_tangki_septik = grid_search.best_score_\n",
    "\n",
    "best_rf_tangki_septik = grid_search.best_estimator_\n",
    "best_rf_tangki_septik.fit(sni_tangki_septik_train_x, sni_tangki_septik_train_y)\n",
    "\n",
    "# For \"Sistem Pembuangan BAB\" data\n",
    "grid_search = GridSearchCV(estimator=rf_sp_bab, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(sni_sp_bab_train_x, sni_sp_bab_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score_sp_bab = grid_search.best_score_\n",
    "\n",
    "best_rf_sp_bab = grid_search.best_estimator_\n",
    "best_rf_sp_bab.fit(sni_sp_bab_train_x, sni_sp_bab_train_y)\n",
    "\n",
    "# For \"IPLT/IPAL\" data\n",
    "grid_search = GridSearchCV(estimator=rf_iplt, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(sni_iplt_train_x, sni_iplt_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score_iplt = grid_search.best_score_\n",
    "\n",
    "best_rf_iplt = grid_search.best_estimator_\n",
    "best_rf_iplt.fit(sni_iplt_train_x, sni_iplt_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tangki Septik Random Forest Classifier with Hyperparameter Tuning Evaluation Results\n",
      "Accuracy:  0.98115\n",
      "Best Score:  1.0\n",
      "Confusion Matrix: \n",
      " [[16766   377]\n",
      " [    0  2857]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     17143\n",
      "           1       0.88      1.00      0.94      2857\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.94      0.99      0.96     20000\n",
      "weighted avg       0.98      0.98      0.98     20000\n",
      "\n",
      "---------------------------------------------\n",
      "Sistem Pembuangan BAB Random Forest Classifier with Hyperparameter Tuning Evaluation Results\n",
      "Accuracy:  0.9979\n",
      "Best Score:  1.0\n",
      "Confusion Matrix: \n",
      " [[19830    42]\n",
      " [    0   128]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19872\n",
      "           1       0.75      1.00      0.86       128\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.88      1.00      0.93     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "---------------------------------------------\n",
      "IPLT/IPAL Random Forest Classifier with Hyperparameter Tuning Evaluation Results\n",
      "Accuracy:  0.945\n",
      "Best Score:  0.9999874999999999\n",
      "Confusion Matrix: \n",
      " [[14524  1100]\n",
      " [    0  4376]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     15624\n",
      "           1       0.80      1.00      0.89      4376\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.90      0.96      0.93     20000\n",
      "weighted avg       0.96      0.94      0.95     20000\n",
      "\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now we will re-evaluate the models using the test data just like before\n",
    "# For \"Tangki Septik\" data\n",
    "sni_tangki_septik_test_y_pred = best_rf_tangki_septik.predict(sni_tangki_septik_test_x)\n",
    "accuracy = accuracy_score(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "class_report = classification_report(sni_tangki_septik_test_y, sni_tangki_septik_test_y_pred)\n",
    "\n",
    "print(\"Tangki Septik Random Forest Classifier with Hyperparameter Tuning Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Best Score: \", best_score_tangki_septik)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"Sistem Pembuangan BAB\" data\n",
    "sni_sp_bab_test_y_pred = best_rf_sp_bab.predict(sni_sp_bab_test_x)\n",
    "accuracy = accuracy_score(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "class_report = classification_report(sni_sp_bab_test_y, sni_sp_bab_test_y_pred)\n",
    "\n",
    "print(\"Sistem Pembuangan BAB Random Forest Classifier with Hyperparameter Tuning Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Best Score: \", best_score_sp_bab)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# For \"IPLT/IPAL\" data\n",
    "sni_iplt_test_y_pred = best_rf_iplt.predict(sni_iplt_test_x)\n",
    "accuracy = accuracy_score(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "conf_matrix = confusion_matrix(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "class_report = classification_report(sni_iplt_test_y, sni_iplt_test_y_pred)\n",
    "\n",
    "print(\"IPLT/IPAL Random Forest Classifier with Hyperparameter Tuning Evaluation Results\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Best Score: \", best_score_iplt)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After all the model and hyperparameter tuning process has completed, the following are the best models for each data\n",
    "# For \"Tangki Septik\" data, the best model is the Random Forest Classifier with Hyperparameter Tuning with accuracy of 0.98115\n",
    "# For \"Sistem Pembuangan BAB\" data, the best model is the Random Forest Classifier with Hyperparameter Tuning with accuracy of 0.9979\n",
    "# For \"IPLT/IPAL\" data, the best model is the Random Forest Classifier with Hyperparameter Tuning with accuracy of 0.945\n",
    "# For \"Saluran Drainase\" data, the best model is the Logistic Regression with accuracy of 1.0\n",
    "\n",
    "# Now, we need to save the models so that we can load them at a later time.\n",
    "import pickle\n",
    "\n",
    "# For \"Tangki Septik\" data, we save the Random Forest Classifier with Hyperparameter Tuning model\n",
    "pickle.dump(best_rf_tangki_septik, open(\"saved_models/best_rf_tangki_septik.pkl\", \"wb\"))\n",
    "# For \"Sistem Pembuangan BAB\" data, we save the Random Forest Classifier with Hyperparameter Tuning model\n",
    "pickle.dump(best_rf_sp_bab, open(\"saved_models/best_rf_sp_bab.pkl\", \"wb\"))\n",
    "# For \"IPLT/IPAL\" data, we save the Random Forest Classifier with Hyperparameter Tuning model\n",
    "pickle.dump(best_rf_iplt, open(\"saved_models/best_rf_iplt.pkl\", \"wb\"))\n",
    "# For \"Saluran Drainase\" data, we save the Logistic Regression model\n",
    "pickle.dump(model_drainase, open(\"saved_models/model_drainase.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of the code is used to load the saved models\n",
    "tangki_septik_model = pickle.load(open(\"saved_models/best_rf_tangki_septik.pkl\", \"rb\"))\n",
    "sp_bab_model = pickle.load(open(\"saved_models/best_rf_sp_bab.pkl\", \"rb\"))\n",
    "iplt_model = pickle.load(open(\"saved_models/best_rf_iplt.pkl\", \"rb\"))\n",
    "drainase_model = pickle.load(open(\"saved_models/model_drainase.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Saluran Drainase_Hierarki Drainase_Primer',\n",
      "       'Saluran Drainase_Hierarki Drainase_Sekunder',\n",
      "       'Saluran Drainase_Hierarki Drainase_Tersier',\n",
      "       'Saluran Drainase_Jenis Drainase_Terbuka',\n",
      "       'Saluran Drainase_Jenis Drainase_Tertutup',\n",
      "       'Saluran Drainase_Bentuk Penampang_Persegi',\n",
      "       'Saluran Drainase_Bentuk Penampang_Segitiga',\n",
      "       'Saluran Drainase_Bentuk Penampang_Setengah Lingkaran',\n",
      "       'Saluran Drainase_Bentuk Penampang_Trapesiun',\n",
      "       'Saluran Drainase_Perkerasan Tepi Drainase_Batuan',\n",
      "       'Saluran Drainase_Perkerasan Tepi Drainase_Kerikil Halus',\n",
      "       'Saluran Drainase_Perkerasan Tepi Drainase_Lempung Kepasiran',\n",
      "       'Saluran Drainase_Perkerasan Tepi Drainase_Pasir Halus',\n",
      "       'Saluran Drainase_Perkerasan Tepi Drainase_Tanah',\n",
      "       'Saluran Drainase_Kondisi Drainase_Terawat',\n",
      "       'Saluran Drainase_Kondisi Drainase_Tidak Terawat',\n",
      "       'Saluran Drainase_Bau Tidak Sedap_Tidak',\n",
      "       'Saluran Drainase_Bau Tidak Sedap_Ya',\n",
      "       'Saluran Drainase_Sedimentasi Drainase_Eceng Gondok',\n",
      "       'Saluran Drainase_Sedimentasi Drainase_Sampah',\n",
      "       'Saluran Drainase_Sedimentasi Drainase_Tanah',\n",
      "       'Saluran Drainase_Sedimentasi Drainase_Tidak Ada'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sni_drainase_train_x.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
